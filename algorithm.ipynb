{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import osr\n",
    "import glob\n",
    "import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import h5py\n",
    "import calendar\n",
    "# Ignore runtime warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# 0. Input variables\n",
    "# Specify file paths\n",
    "# Path of current workspace\n",
    "path_workspace = '/Users/binfang/Documents/SMAP_CONUS/codes_py'\n",
    "# Path of Land mask\n",
    "path_lmask = '/Volumes/MyPassport/SMAP_Project/Datasets/Lmask'\n",
    "# Path of processed data\n",
    "path_procdata = '/Volumes/MyPassport/SMAP_Project/Datasets/processed_data'\n",
    "# Path of source MODIS data\n",
    "path_modis = '/Users/binfang/Downloads/Processing/HDF'\n",
    "# Path of MODIS data for SM downscaling model input\n",
    "path_modis_ip = '/Users/binfang/Downloads/Processing/Model_Input'\n",
    "# Path of SM model output\n",
    "path_model_op = '/Users/binfang/Downloads/Processing/Model_Output'\n",
    "# Path of downscaled SM\n",
    "path_smap_sm_ds = '/Users/binfang/Downloads/Processing/Downscale'\n",
    "\n",
    "lst_folder = '/MYD11A1/'\n",
    "ndvi_folder = '/MYD13A2/'\n",
    "smap_sm_9km_name = ['smap_sm_9km_am', 'smap_sm_9km_pm']\n",
    "\n",
    "# Load in geo-location parameters\n",
    "os.chdir(path_workspace)\n",
    "f = h5py.File(\"ds_parameters.hdf5\", \"r\")\n",
    "varname_list = ['lat_world_max', 'lat_world_min', 'lon_world_max', 'lon_world_min',\n",
    "                'lat_world_ease_9km', 'lon_world_ease_9km', 'lat_world_ease_1km', 'lon_world_ease_1km',\n",
    "                'lat_world_ease_25km', 'lon_world_ease_25km', 'row_world_ease_1km_from_25km_ind',\n",
    "                'col_world_ease_1km_from_25km_ind', 'row_world_ease_1km_from_9km_ind', 'col_world_ease_1km_from_9km_ind',\n",
    "                'row_world_ease_9km_from_1km_ext33km_ind', 'col_world_ease_9km_from_1km_ext33km_ind']\n",
    "\n",
    "for x in range(len(varname_list)):\n",
    "    var_obj = f[varname_list[x]][()]\n",
    "    exec(varname_list[x] + '= var_obj')\n",
    "    del(var_obj)\n",
    "f.close()\n",
    "\n",
    "# Generate sequence of string between start and end dates (Year + DOY)\n",
    "start_date = '2015-04-01'\n",
    "end_date = '2019-10-31'\n",
    "\n",
    "start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "end_date = datetime.datetime.strptime(end_date, '%Y-%m-%d').date()\n",
    "delta_date = end_date - start_date\n",
    "\n",
    "date_seq = []\n",
    "for i in range(delta_date.days + 1):\n",
    "    date_str = start_date + datetime.timedelta(days=i)\n",
    "    date_seq.append(str(date_str.timetuple().tm_year) + str(date_str.timetuple().tm_yday).zfill(3))\n",
    "\n",
    "# Count how many days for a specific year\n",
    "yearname = np.linspace(2015, 2019, 5, dtype='int')\n",
    "monthnum = np.linspace(1, 12, 12, dtype='int')\n",
    "monthname = np.arange(1, 13)\n",
    "monthname = [str(i).zfill(2) for i in monthname]\n",
    "\n",
    "daysofyear = []\n",
    "for idt in range(len(yearname)):\n",
    "    if idt == 0:\n",
    "        f_date = datetime.date(yearname[idt], monthnum[3], 1)\n",
    "        l_date = datetime.date(yearname[idt], monthnum[-1], 31)\n",
    "        delta_1y = l_date - f_date\n",
    "        daysofyear.append(delta_1y.days + 1)\n",
    "    else:\n",
    "        f_date = datetime.date(yearname[idt], monthnum[0], 1)\n",
    "        l_date = datetime.date(yearname[idt], monthnum[-1], 31)\n",
    "        delta_1y = l_date - f_date\n",
    "        daysofyear.append(delta_1y.days + 1)\n",
    "\n",
    "daysofyear = np.asarray(daysofyear)\n",
    "\n",
    "# Find the indices of each month in the list of days between 2015 - 2018\n",
    "nlpyear = 1999 # non-leap year\n",
    "lpyear = 2000 # leap year\n",
    "daysofmonth_nlp = np.array([calendar.monthrange(nlpyear, x)[1] for x in range(1, len(monthnum)+1)])\n",
    "ind_nlp = [np.arange(daysofmonth_nlp[0:x].sum(), daysofmonth_nlp[0:x+1].sum()) for x in range(0, len(monthnum))]\n",
    "daysofmonth_lp = np.array([calendar.monthrange(lpyear, x)[1] for x in range(1, len(monthnum)+1)])\n",
    "ind_lp = [np.arange(daysofmonth_lp[0:x].sum(), daysofmonth_lp[0:x+1].sum()) for x in range(0, len(monthnum))]\n",
    "ind_iflpr = np.array([int(calendar.isleap(yearname[x])) for x in range(len(yearname))]) # Find out leap years\n",
    "# Generate a sequence of the days of months for all years\n",
    "daysofmonth_seq = np.array([np.tile(daysofmonth_nlp[x], len(yearname)) for x in range(0, len(monthnum))])\n",
    "daysofmonth_seq[1, :] = daysofmonth_seq[1, :] + ind_iflpr # Add leap days to February\n",
    "\n",
    "modis_ndvi_days = np.array([9,  25,  41,  57,  73,  89, 105, 121, 137, 153, 169, 185, 201,\n",
    "       217, 233, 249, 265, 281, 297, 313, 329, 345, 361])\n",
    "oneyeardays_sq = np.arange(1, 367)\n",
    "modis_ndvi_days_ind = np.array([modis_ndvi_days[np.where(np.absolute(oneyeardays_sq[x] - modis_ndvi_days) ==\n",
    "                                                np.amin((np.absolute(oneyeardays_sq[x] - modis_ndvi_days))))].item(0)\n",
    "                       for x in range(len(oneyeardays_sq))])\n",
    "\n",
    "# Convert the 1 km from 9 km/25 km match table files to 1-d linear\n",
    "col_meshgrid_from_9km, row_meshgrid_from_9km = np.meshgrid(col_world_ease_1km_from_9km_ind, row_world_ease_1km_from_9km_ind)\n",
    "col_meshgrid_from_9km = col_meshgrid_from_9km.reshape(1, -1)\n",
    "row_meshgrid_from_9km = row_meshgrid_from_9km.reshape(1, -1)\n",
    "\n",
    "col_meshgrid_from_25km, row_meshgrid_from_25km = np.meshgrid(col_world_ease_1km_from_25km_ind, row_world_ease_1km_from_25km_ind)\n",
    "col_meshgrid_from_25km = col_meshgrid_from_25km.reshape(1, -1)\n",
    "row_meshgrid_from_25km = row_meshgrid_from_25km.reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# 1. Implement the VIS/IR downscaling model on MODIS LST difference to calculate 1 km soil moisture\n",
    "\n",
    "# Load in model coefficient files\n",
    "os.chdir(path_procdata)\n",
    "f = h5py.File(\"ds_model_coef.hdf5\", \"r\")\n",
    "varname_list = list(f.keys())\n",
    "varname_list = varname_list[0:24] # Load in only monthly linear regression model coefficients\n",
    "for x in range(len(varname_list)):\n",
    "    var_obj = f[varname_list[x]][()]\n",
    "    exec(varname_list[x] + '= var_obj')\n",
    "    del(var_obj)\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n",
       "         9,   9,   9,   9,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
       "        25,  25,  25,  25,  25,  25,  25,  41,  41,  41,  41,  41,  41,\n",
       "        41,  41,  41,  41,  41,  41,  41,  41,  41,  41,  57,  57,  57,\n",
       "        57,  57,  57,  57,  57,  57,  57,  57,  57,  57,  57,  57,  57,\n",
       "        73,  73,  73,  73,  73,  73,  73,  73,  73,  73,  73,  73,  73,\n",
       "        73,  73,  73,  89,  89,  89,  89,  89,  89,  89,  89,  89,  89,\n",
       "        89,  89,  89,  89,  89,  89, 105, 105, 105, 105, 105, 105, 105,\n",
       "       105, 105, 105, 105, 105, 105, 105, 105, 105, 121, 121, 121, 121,\n",
       "       121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 137,\n",
       "       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,\n",
       "       137, 137, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,\n",
       "       153, 153, 153, 153, 153, 169, 169, 169, 169, 169, 169, 169, 169,\n",
       "       169, 169, 169, 169, 169, 169, 169, 169, 185, 185, 185, 185, 185,\n",
       "       185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217,\n",
       "       217, 217, 217, 217, 233, 233, 233, 233, 233, 233, 233, 233, 233,\n",
       "       233, 233, 233, 233, 233, 233, 233, 249, 249, 249, 249, 249, 249,\n",
       "       249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 265, 265, 265,\n",
       "       265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265,\n",
       "       281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281, 281,\n",
       "       281, 281, 281, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297,\n",
       "       297, 297, 297, 297, 297, 297, 313, 313, 313, 313, 313, 313, 313,\n",
       "       313, 313, 313, 313, 313, 313, 313, 313, 313, 329, 329, 329, 329,\n",
       "       329, 329, 329, 329, 329, 329, 329, 329, 329, 329, 329, 329, 345,\n",
       "       345, 345, 345, 345, 345, 345, 345, 345, 345, 345, 345, 345, 345,\n",
       "       345, 345, 361, 361, 361, 361, 361, 361, 361, 361, 361, 361, 361,\n",
       "       361, 361])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modis_ndvi_days_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matsize_smap_sm_model_1day = [len(lat_world_ease_1km), len(lon_world_ease_1km)]\n",
    "smap_sm_model_mat_init_1day = np.empty(matsize_smap_sm_model_1day, dtype='float32')\n",
    "smap_sm_model_mat_init_1day[:] = np.nan\n",
    "smap_sm_model_mat_init_1day_1dim = smap_sm_model_mat_init_1day.reshape(1, -1)\n",
    "\n",
    "for iyr in range(4, len(yearname)):\n",
    "\n",
    "    for idt in [303]:#range(daysofyear[iyr]):\n",
    "\n",
    "        # Load in MODIS LST data\n",
    "        modis_lst_file_path_1 = path_modis_ip + lst_folder + str(yearname[iyr]) + '/' + \\\n",
    "                                'modis_lst_1km_' + str(yearname[iyr]) + str(idt+1).zfill(3) + '.tif'\n",
    "        if idt < daysofyear[iyr]:\n",
    "            modis_lst_file_path_2 = path_modis_ip + lst_folder + str(yearname[iyr]) + '/' + \\\n",
    "                                    'modis_lst_1km_' + str(yearname[iyr]) + str(idt+2).zfill(3) + '.tif'\n",
    "        elif iyr < len(yearname)-1:\n",
    "            modis_lst_file_path_2 = path_modis_ip + lst_folder + str(yearname[iyr+1]) + '/' + \\\n",
    "                                    'modis_lst_1km_' + str(yearname[iyr+1]) + str(1).zfill(3) + '.tif'\n",
    "        else:\n",
    "            modis_lst_file_path_2 = 'None'\n",
    "\n",
    "        # Find the if the files exist in the directory\n",
    "        if os.path.exists(modis_lst_file_path_1) == True and os.path.exists(modis_lst_file_path_2) == True:\n",
    "\n",
    "            ds_lst_1 = gdal.Open(modis_lst_file_path_1)\n",
    "            ds_lst_2 = gdal.Open(modis_lst_file_path_2)\n",
    "            ds_lst_1_day = ds_lst_1.GetRasterBand(1).ReadAsArray()\n",
    "            ds_lst_1_night = ds_lst_1.GetRasterBand(2).ReadAsArray()\n",
    "            ds_lst_2_night = ds_lst_2.GetRasterBand(2).ReadAsArray()\n",
    "\n",
    "            ds_lst_am = ds_lst_1_day - ds_lst_1_night\n",
    "            ds_lst_pm = ds_lst_1_day - ds_lst_2_night\n",
    "\n",
    "            ds_lst_am = ds_lst_am.reshape(1, -1)\n",
    "            ds_lst_pm = ds_lst_pm.reshape(1, -1)\n",
    "            ds_lst_am_ind = np.where(~np.isnan(ds_lst_am))[1]\n",
    "            ds_lst_pm_ind = np.where(~np.isnan(ds_lst_pm))[1]\n",
    "            ds_lst_am_nonnan = ds_lst_am[0, ds_lst_am_ind]\n",
    "            ds_lst_pm_nonnan = ds_lst_pm[0, ds_lst_pm_ind]\n",
    "\n",
    "            # Load in MODIS NDVI data\n",
    "            modis_ndvi_file_path = path_modis_ip + ndvi_folder + str(yearname[iyr]) + '/' + \\\n",
    "                                   'modis_ndvi_1km_' + str(yearname[iyr]) + str(modis_ndvi_days_ind[idt]).zfill(3) + '.tif'\n",
    "\n",
    "            ds_ndvi = gdal.Open(modis_ndvi_file_path)\n",
    "            ds_ndvi_idx = ds_ndvi.GetRasterBand(1).ReadAsArray()\n",
    "            ds_ndvi_idx = np.nan_to_num(ds_ndvi_idx)\n",
    "            ds_ndvi_idx = np.fix(ds_ndvi_idx*10).astype(int)\n",
    "            ds_ndvi_idx[np.where(ds_ndvi_idx >= 10)] = 9\n",
    "\n",
    "            del(ds_lst_2, ds_lst_1_day, ds_lst_1_night, ds_lst_2_night, ds_ndvi)\n",
    "\n",
    "\n",
    "            # Extract coefficient and intercept from the position indices of corresponding monthly model file\n",
    "            ds_ndvi_idx = ds_ndvi_idx.reshape(1, -1)\n",
    "\n",
    "            month_id = str(datetime.datetime.strptime(str(yearname[iyr]) + '+' + str(idt+1).zfill(3), '%Y+%j').month).zfill(2)\n",
    "            exec('coef_mat_am = ' + 'coef_mat_am_' + month_id)\n",
    "            exec('coef_mat_pm = ' + 'coef_mat_pm_' + month_id)\n",
    "\n",
    "            # AM SM\n",
    "            coef_mat_am_coef = np.array([coef_mat_am[row_meshgrid_from_25km[0, ds_lst_am_ind[x]],\n",
    "                                                     col_meshgrid_from_25km[0, ds_lst_am_ind[x]],\n",
    "                                                     ds_ndvi_idx[0, ds_lst_am_ind[x]]*2] for x in range(len(ds_lst_am_ind))])\n",
    "            coef_mat_am_intc = np.array([coef_mat_am[row_meshgrid_from_25km[0, ds_lst_am_ind[x]],\n",
    "                                                     col_meshgrid_from_25km[0, ds_lst_am_ind[x]],\n",
    "                                                     ds_ndvi_idx[0, ds_lst_am_ind[x]]*2+1] for x in range(len(ds_lst_am_ind))])\n",
    "            smap_sm_1km_am_model_nonnan = coef_mat_am_coef * ds_lst_am_nonnan + coef_mat_am_intc\n",
    "\n",
    "            smap_sm_1km_am_model = np.copy(smap_sm_model_mat_init_1day_1dim)\n",
    "            smap_sm_1km_am_model[0, ds_lst_am_ind] = smap_sm_1km_am_model_nonnan\n",
    "            smap_sm_1km_am_model[np.where(smap_sm_1km_am_model <= 0)] = np.nan\n",
    "            smap_sm_1km_am_model = smap_sm_1km_am_model.reshape(matsize_smap_sm_model_1day)\n",
    "\n",
    "            # PM SM\n",
    "            coef_mat_pm_coef = np.array([coef_mat_pm[row_meshgrid_from_25km[0, ds_lst_pm_ind[x]],\n",
    "                                                     col_meshgrid_from_25km[0, ds_lst_pm_ind[x]],\n",
    "                                                     ds_ndvi_idx[0, ds_lst_pm_ind[x]]*2] for x in range(len(ds_lst_pm_ind))])\n",
    "            coef_mat_pm_intc = np.array([coef_mat_pm[row_meshgrid_from_25km[0, ds_lst_pm_ind[x]],\n",
    "                                                     col_meshgrid_from_25km[0, ds_lst_pm_ind[x]],\n",
    "                                                     ds_ndvi_idx[0, ds_lst_pm_ind[x]]*2+1] for x in range(len(ds_lst_pm_ind))])\n",
    "            smap_sm_1km_pm_model_nonnan = coef_mat_pm_coef * ds_lst_pm_nonnan + coef_mat_pm_intc\n",
    "\n",
    "            smap_sm_1km_pm_model = np.copy(smap_sm_model_mat_init_1day_1dim)\n",
    "            smap_sm_1km_pm_model[0, ds_lst_pm_ind] = smap_sm_1km_pm_model_nonnan\n",
    "            smap_sm_1km_pm_model[np.where(smap_sm_1km_pm_model <= 0)] = np.nan\n",
    "            smap_sm_1km_pm_model = smap_sm_1km_pm_model.reshape(matsize_smap_sm_model_1day)\n",
    "\n",
    "            del(ds_lst_am, ds_lst_pm, ds_lst_am_ind, ds_lst_pm_ind, ds_lst_am_nonnan, ds_lst_pm_nonnan, ds_ndvi_idx,\n",
    "                month_id, coef_mat_am_coef, coef_mat_am_intc, smap_sm_1km_am_model_nonnan, coef_mat_pm_coef,\n",
    "                coef_mat_pm_intc, smap_sm_1km_pm_model_nonnan)\n",
    "\n",
    "\n",
    "            # Save the daily 1 km SM model output to Geotiff files\n",
    "            # Build output path\n",
    "            os.chdir(path_model_op + '/' + str(yearname[iyr]))\n",
    "\n",
    "            # Create a raster of EASE grid projection at 1 km resolution\n",
    "            out_ds_tiff = gdal.GetDriverByName('GTiff').Create('smap_sm_1km_' + str(yearname[iyr]) + str(idt+1).zfill(3) + '.tif',\n",
    "                                                               len(lon_world_ease_1km), len(lat_world_ease_1km), 2, # Number of bands\n",
    "                                                               gdal.GDT_Float32, ['COMPRESS=LZW', 'TILED=YES'])\n",
    "            out_ds_tiff.SetGeoTransform(ds_lst_1.GetGeoTransform())\n",
    "            out_ds_tiff.SetProjection(ds_lst_1.GetProjection())\n",
    "\n",
    "            # Write each band to Geotiff file\n",
    "            out_ds_tiff.GetRasterBand(1).WriteArray(smap_sm_1km_am_model)\n",
    "            out_ds_tiff.GetRasterBand(1).SetNoDataValue(0)\n",
    "            out_ds_tiff.GetRasterBand(2).WriteArray(smap_sm_1km_pm_model)\n",
    "            out_ds_tiff.GetRasterBand(2).SetNoDataValue(0)\n",
    "            out_ds_tiff = None  # close dataset to write to disc\n",
    "\n",
    "            print(str(yearname[iyr]) + str(idt+1).zfill(3))\n",
    "            del(smap_sm_1km_am_model, smap_sm_1km_pm_model, ds_lst_1, out_ds_tiff)\n",
    "\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019244\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# 2. Downscale the 1km soil moisture model output by 9 km SMAP L2 soil moisture data\n",
    "\n",
    "# Create initial EASE grid projection matrices\n",
    "smap_sm_1km_agg_init = np.empty([len(lat_world_ease_9km), len(lon_world_ease_9km)], dtype='float32')\n",
    "smap_sm_1km_agg_init[:] = np.nan\n",
    "smap_sm_1km_disagg_init = np.empty([len(lat_world_ease_1km), len(lon_world_ease_1km)], dtype='float32')\n",
    "smap_sm_1km_disagg_init = smap_sm_1km_disagg_init.reshape(1, -1)\n",
    "smap_sm_1km_disagg_init[:] = np.nan\n",
    "smap_sm_1km_ds_init = np.empty([len(lat_world_ease_1km), len(lon_world_ease_1km), 2], dtype='float32')\n",
    "smap_sm_1km_ds_init[:] = np.nan\n",
    "\n",
    "for iyr in range(4, len(yearname)):\n",
    "\n",
    "    for imo in range(8, len(monthname)):\n",
    "\n",
    "        # Load in SMAP 9km SM data\n",
    "        smap_file_path = path_procdata + '/smap_sm_9km_' + str(yearname[iyr]) + monthname[imo] + '.hdf5'\n",
    "\n",
    "        # Find the if the file exists in the directory\n",
    "        if os.path.exists(smap_file_path) == True:\n",
    "            f_smap_9km = h5py.File(smap_file_path, \"r\")\n",
    "            varname_list_smap_ip = list(f_smap_9km.keys())\n",
    "            for x in range(len(varname_list_smap_ip)):\n",
    "                var_obj = f_smap_9km[varname_list_smap_ip[x]][()]\n",
    "                exec(smap_sm_9km_name[x] + '= var_obj')\n",
    "                del(var_obj)\n",
    "            f_smap_9km.close()\n",
    "\n",
    "            smap_sm_9km = np.concatenate((smap_sm_9km_am, smap_sm_9km_pm), axis=2)\n",
    "            del(smap_sm_9km_am, smap_sm_9km_pm)\n",
    "\n",
    "            # Load in MODIS LST data\n",
    "            month_begin = daysofmonth_seq[0:imo, iyr].sum()\n",
    "            month_end = daysofmonth_seq[0:imo + 1, iyr].sum()\n",
    "            month_lenth = month_end - month_begin\n",
    "            for idt in range(month_lenth):\n",
    "\n",
    "                smap_sm_1km_file_path = path_model_op + '/' + str(yearname[iyr]) + '/smap_sm_1km_' + str(yearname[iyr]) + \\\n",
    "                                        str(month_begin+idt+1).zfill(3) + '.tif'\n",
    "\n",
    "                if os.path.exists(smap_sm_1km_file_path) == True:\n",
    "                    ds_smap_sm_1km = gdal.Open(smap_sm_1km_file_path)\n",
    "                    smap_sm_1km = ds_smap_sm_1km.ReadAsArray()\n",
    "                    smap_sm_1km = np.transpose(smap_sm_1km, (1, 2, 0))\n",
    "                    smap_sm_1km_ds_output = np.copy(smap_sm_1km_ds_init)\n",
    "\n",
    "                    for idf in range(2):\n",
    "                        # Aggregate 1km SM model output to 9 km resolution, and calculate its difference with 9 km SMAP SM\n",
    "                        smap_sm_1km_agg = np.copy(smap_sm_1km_agg_init)\n",
    "\n",
    "                        smap_sm_1km_1file = smap_sm_1km[:, :, idf]\n",
    "                        smap_sm_1km_1file_1dim = smap_sm_1km_1file.reshape(1, -1)\n",
    "                        smap_sm_1km_1file_ind = np.where(~np.isnan(smap_sm_1km_1file_1dim))[1]\n",
    "\n",
    "                        smap_sm_1km_agg = np.array \\\n",
    "                            ([np.nanmean(smap_sm_1km_1file[row_world_ease_9km_from_1km_ext33km_ind[x], :], axis=0)\n",
    "                              for x in range(len(lat_world_ease_9km))])\n",
    "                        smap_sm_1km_agg = np.array \\\n",
    "                            ([np.nanmean(smap_sm_1km_agg[:, col_world_ease_9km_from_1km_ext33km_ind[y]], axis=1)\n",
    "                              for y in range(len(lon_world_ease_9km))])\n",
    "                        smap_sm_1km_agg = np.fliplr(np.rot90(smap_sm_1km_agg, 3))\n",
    "                        smap_sm_1km_delta = smap_sm_9km[:, :, month_lenth*idf+idt] - smap_sm_1km_agg\n",
    "                        # smap_sm_1km_delta = smap_sm_1km_delta.reshape(1, -1)\n",
    "\n",
    "                        smap_sm_1km_delta_disagg = np.array([smap_sm_1km_delta[row_meshgrid_from_9km[0, smap_sm_1km_1file_ind[x]],\n",
    "                                                  col_meshgrid_from_9km[0, smap_sm_1km_1file_ind[x]]]\n",
    "                                      for x in range(len(smap_sm_1km_1file_ind))])\n",
    "                        smap_sm_1km_disagg = np.copy(smap_sm_1km_disagg_init)\n",
    "                        smap_sm_1km_disagg[0, smap_sm_1km_1file_ind] = smap_sm_1km_delta_disagg\n",
    "                        smap_sm_1km_disagg = smap_sm_1km_disagg.reshape(len(lat_world_ease_1km), len(lon_world_ease_1km))\n",
    "\n",
    "                        smap_sm_1km_ds = smap_sm_1km_1file + smap_sm_1km_disagg\n",
    "                        smap_sm_1km_ds[np.where(smap_sm_1km_ds <= 0)] = np.nan\n",
    "                        smap_sm_1km_ds_output[:, :, idf] = smap_sm_1km_ds\n",
    "                        del(smap_sm_1km_agg, smap_sm_1km_1file, smap_sm_1km_1file_1dim, smap_sm_1km_1file_ind, smap_sm_1km_delta,\n",
    "                            smap_sm_1km_delta_disagg, smap_sm_1km_disagg, smap_sm_1km_ds)\n",
    "\n",
    "                    # Save the daily 1 km SM model output to Geotiff files\n",
    "                    # Build output path\n",
    "                    os.chdir(path_smap_sm_ds + '/' + str(yearname[iyr]))\n",
    "\n",
    "                    # Create a raster of EASE grid projection at 1 km resolution\n",
    "                    out_ds_tiff = gdal.GetDriverByName('GTiff').Create\\\n",
    "                        ('smap_sm_1km_ds_' + str(yearname[iyr]) + str(month_begin+idt+1).zfill(3) + '.tif',\n",
    "                         len(lon_world_ease_1km), len(lat_world_ease_1km), 2, # Number of bands\n",
    "                         gdal.GDT_Float32, ['COMPRESS=LZW', 'TILED=YES'])\n",
    "                    out_ds_tiff.SetGeoTransform(ds_smap_sm_1km.GetGeoTransform())\n",
    "                    out_ds_tiff.SetProjection(ds_smap_sm_1km.GetProjection())\n",
    "\n",
    "                    # Loop write each band to Geotiff file\n",
    "                    for idf in range(2):\n",
    "                        out_ds_tiff.GetRasterBand(idf + 1).WriteArray(smap_sm_1km_ds_output[:, :, idf])\n",
    "                        out_ds_tiff.GetRasterBand(idf + 1).SetNoDataValue(0)\n",
    "                    out_ds_tiff = None  # close dataset to write to disc\n",
    "\n",
    "                    print(str(yearname[iyr]) + str(month_begin+idt+1).zfill(3))\n",
    "                    del (smap_sm_1km_ds_output, ds_smap_sm_1km, out_ds_tiff)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(304, 304)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(304, 304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idt=303 \n",
    "iyr=4\n",
    "smap_file_path = path_modis_ip + lst_folder + str(yearname[iyr]) + '/' + \\\n",
    "                                'modis_lst_1km_' + str(yearname[iyr]) + str(idt+1).zfill(3) + '.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(smap_file_path) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
